{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport datetime\ntimestamp_exec_start = time.time()\n\nfiles = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            files.append(os.path.join(dirname, filename))\nprint(\"Processed \",len(files),\"files\")\n\nlabels_dict = {\"B_A-\":0,\"B_F-\":1,\"B_TA\":2,\"B_PT\":3,\"M_DC\":4,\"M_LC\":5,\"M_MC\":6,\"M_PC\":7}  # for 8 class problem\nlabels_dict_simple = {\"B\":0,\"M\":1}                                                       # for 2 class problem\nREDUCED_CLASSES = False\n\nX = []\nY = []\nM = []\nfor f in files:\n    x = f.split(\"/\") # break up the path\n    x = x[-1:][0]    # extract the file name\n    X.append(str(f))\n    if REDUCED_CLASSES:\n        Y.append(int(labels_dict_simple[x[4]]))\n    else:\n        Y.append(int(labels_dict[x[4:8]]))\n    m = f.split(\"-\")\n    m = m[-2]\n    M.append(m)\n\ndata = {\"images\":X,\"labels\":Y,\"magnification\":M }\nimages_df = pd.DataFrame(data, columns = ['images','labels','magnification'])\nimages_df_40 = images_df.loc[images_df['magnification']=='40'].drop(['magnification'], axis=1)\nimages_df_100 = images_df.loc[images_df['magnification']=='100'].drop(['magnification'], axis=1)\nimages_df_200 = images_df.loc[images_df['magnification']=='200'].drop(['magnification'], axis=1)\nimages_df_400 = images_df.loc[images_df['magnification']=='400'].drop(['magnification'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# DELETE AFTER APPENDING TO NB ############################################################\nbatch_size = 16\n\nimport torchvision.transforms as transforms\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, df_data,transform=None):\n        super().__init__()\n        self.df = df_data.values\n        \n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path,label = self.df[index]\n        \n        image = cv2.imread(img_path)\n        image = cv2.resize(image, (224,224))\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n    \ntrans_valid = transforms.Compose([transforms.ToPILImage(),                    \n                                  transforms.Pad(64, padding_mode='reflect'),\n                                  transforms.Resize(224, interpolation = 2),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n\n##############################################################################################\n\ndataset_img40 = MyDataset(df_data=images_df_40, transform=trans_valid)\nloader_img40 = DataLoader(dataset = dataset_img40, batch_size=batch_size//2, shuffle=False, num_workers=0)\n\ndataset_img100 = MyDataset(df_data=images_df_100, transform=trans_valid)\nloader_img100 = DataLoader(dataset = dataset_img100, batch_size=batch_size//2, shuffle=False, num_workers=0)\n\ndataset_img200 = MyDataset(df_data=images_df_200, transform=trans_valid)\nloader_img200 = DataLoader(dataset = dataset_img200, batch_size=batch_size//2, shuffle=False, num_workers=0)\n\ndataset_img400 = MyDataset(df_data=images_df_400, transform=trans_valid)\nloader_img400 = DataLoader(dataset = dataset_img400, batch_size=batch_size//2, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}